---
title: "10.15"
date: "2025-10-13"
source: "inbox/10.15.pdf"
format: "PDF Document"
pages: "1"
converted: "2025-11-11 14:57:20"
---

# 10.15

**Pages:** 1


## Page 1

10.15
Summary:
This passage introduces a compiler the team develops, Mirage Persistent 
Kernel MPK, to transform LLM inference into a single megakernel — a fused 
GPU kernel that performs all necessary (layer-to-layer) computation and (inter-
GPU communication in one launch, to reduce the latency in LLM inference. It 
manages to eliminate kernel launch overhead, enable software pipelining across 
layers, and overlap computation and communication. The MPK compiler optimizes 
the CDG(s) to task graph(s) while the MPK runtime executes the task graph within 
a megakernel to achieve high throughput and low latency.
Questions:
 What's the pros and cons of megakernel as compared to traditional more fine-
grained GPU kernels?
Pros: Eliminate kernel launch overhead, enable software pipelining across layers, 
and overlap computation and communication.
Cons: 
Resource pressure: One big kernel hoards registers/shared memory, which 
can cap active warps and hurt latency hiding.
Preemption risks: Long-running kernels are harder to preempt; a bug can stall 
the whole pipeline rather than one stage.
 Do you think it's feasible to build a megakernel that incorporates speculative 
decoding? How?
Feasible. By structuring the megakernel as a persistent, event-driven pipeline with 
warps specializing in “proposeˮ and “verify,ˮ shared KV paging, and careful 
buffering. The win is fewer launches and maximal overlap. The cost is substantial 
engineering and tighter hardware-resource constraints.
10 . 15
1